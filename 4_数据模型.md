

Hive中包含4中数据模型：Tabel、ExternalTable、Partition、Bucket。


Table：类似与传统数据库中的Table，每一个Table在Hive中都有一个相应的目录来存储数据。例如：一个表t，它在HDFS中的路径为：\/user\/hive\/warehouse\/t。
Partition：类似于传统数据库中划分列的索引。在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition数据都存储在对应的目录中。例如：t表中包含ds和city两个Partition，则对应于ds=2014，city=beijing的HDFS子目录为：\/user\/hive\/warehouse\/t\/ds=2014\/city=Beijing； 需要注意的是，分区列是表的伪列，表数据文件中并不存在这个分区列的数据。
Buckets：对指定列计算的hash，根据hash值切分数据，目的是为了便于并行，每一个Buckets对应一个文件。将user列分数至32个Bucket上，首先对user列的值计算hash，比如，对应hash=0的HDFS目录为：\/user\/hive\/warehouse\/t\/ds=2014\/city=Beijing\/part-00000；对应hash=20的目录为：\/user\/hive\/warehouse\/t\/ds=2014\/city=Beijing\/part-00020。
External Table指向已存在HDFS中的数据，可创建Partition。Managed Table创建和数据加载过程，可以用统一语句实现，实际数据被转移到数据仓库目录中，之后对数据的访问将会直接在数据仓库的目录中完成。删除表时，表中的数据和元数据都会删除。External Table只有一个过程，因为加载数据和创建表是同时完成。数据是存储在Location后面指定的HDFS路径中的，并不会移动到数据仓库中。

